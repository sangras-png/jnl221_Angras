<!-- This is an HTML page for the JNL221 class' first repository.-->

<!DOCTYPE html>
<html>
	<head>
	
		<meta charset="utf-8">
		<title>First repository</title>
		<link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,400,300,600,700&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
		<link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
	
		<!-- This is where this page's style sheet is defined. -->
		<link type="text/css" rel="stylesheet" href="index.css" />

	</head>
	<body>
	
		<!-- This is the header row for this page. -->
		<div id="intro">
			<h1>SIYA ANGRAS</h1>
			<h4>Syracuse University, Fall 2025</h4>
		</div>

		<section>
			<p>What surprised me the most in this documentary is around at the 20 minute mark, where the following quote was said by author, Virginia Eubanks, , “The future is already here its just not evenly distributed, what they usually mean by that is that rich people tend to get the tools first and then poor people are the ones that get it last. But what I have found is the absolute reverse, the most punitive, most invasive, most surveillance focused tools that we have they go into poor and working communities first. and then if they work in this environment where there is this sort of low expectation that peoples rights will be respected, then they get ported out into other communities.” 

This entire quote really stuck with me, I think it is because this was contrary to my belief. I have always viewed technology as a luxury, rather than something that would be more available in impoverished communities. This concept led to something else that surprised me, which is when the idea of how data and technology actually can add to discriminatory and unequal systems because it was produced in these systems. </p>

<p> I have seen AI depicted in pop culture as mainly a high tech, unusual, and very visible form of technologically where the people involved are very aware that they are participating in the technology. I have also seen dystopian episodes, like in the TV show Black Mirror, where AI is allowed in by people and then overtaken by this technology. I think this is different from what was shown in the documentary because it is shown to be interacting with us in all areas of life. There were examples of algorithms, that we do not know even the operation toolbox or regulations of, deciding things such as housing, jobs, and other things that have been fought for to be equal forever. But, we do not even know the intentions of the people who are programming these things. 

<p>
	<p> My first two questions would be: Are algorithms being programmed to have cultural biases? Or are algorithms being programmed by individuals that do not have awareness of these culture biases and do not know how to program with awareness to avoid bias incidents? 

The two specific incidents that brought those questions to my attention were Incidents 16 and 14, amongst others. I believe these questions, “ allows you to organize your thoughts and ensure you get the answers you need,” which is what the article advised. 

Following the suggestions in the readings, a disprovable and specific hypothesis I have about this data set is: Communities that experience biases in social settings in western society are experiencing those same biases when searching on algorithms. 

I believe this is specific because it narrows down to who is experiencing biases and specifically in what community. To make this more specific and to critique my own hypothesis, I believe I could use a specific example and discuss a particular group of people such as: The search system algorithms are not checking for gender or racial biases when suggesting search options. My evidence are the following cases to determine frequency but I am sure there are more: 18, 13, 19, 37, 47, 36, 16, 14 and more. 
<p> 
		</section>

		<div id="end">
			<h4>this page was published on github pages. fonts: montserrat, open sans.</h4>
		</div>


	</body>
</html>